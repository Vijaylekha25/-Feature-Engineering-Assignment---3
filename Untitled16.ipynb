{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a086e0b-f87f-42e9-b3ee-de704705a0f1",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9afeb3-f1bf-401c-8c84-5c448d124846",
   "metadata": {},
   "source": [
    "Answer- Min-Max scaling is a data preprocessing technique used to rescale numeric features to a specific range, typically between 0 and 1. It is done by subtracting the minimum value of the feature and then dividing by the range of the feature (the maximum value minus the minimum value). This method preserves the original distribution of the data while scaling it to a specified range.\n",
    "\n",
    "Example:\n",
    "Suppose we have a feature representing house prices with values ranging from $100,000 to $500,000. By applying Min-Max scaling, we can transform these values to a range between 0 and 1, making it easier for machine learning algorithms to process. For instance, a house priced at $250,000 would be scaled to 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc93bf-b465-4995-864d-c271300b1dfb",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d54370-963c-4822-b18e-75f6f76c3e91",
   "metadata": {},
   "source": [
    "Answer- The Unit Vector technique in feature scaling, also known as normalization, scales individual samples to have unit norm (i.e., a magnitude of 1). Unlike Min-Max scaling, which scales features to a specific range, Unit Vector scaling focuses on the direction of the data rather than its magnitude.\n",
    "\n",
    "Example:\n",
    "Consider a dataset with two features: age and income. Using Unit Vector scaling, each sample's values are divided by its Euclidean norm, ensuring that the resulting vector has a magnitude of 1. This normalization technique is useful when the magnitude of features is not important, and only their direction matters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2409f7-b7fb-40d8-9bb5-06b2350cc94e",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc85d1-fbb8-49cf-8a89-91ed625cb0fd",
   "metadata": {},
   "source": [
    "Answer- PCA (Principal Component Analysis) is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional representation while preserving most of the variance in the data. It does this by identifying the principal components, which are linear combinations of the original features that capture the maximum variance.\n",
    "\n",
    "Example:\n",
    "Suppose we have a dataset with numerous features representing various aspects of a customer's behavior on an e-commerce website. By applying PCA, we can reduce the dimensionality of the dataset while retaining most of the information, making it easier to visualize and analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8bdca5-c241-47fc-a006-533e9169f10e",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b0941f-0634-48dd-a71e-264876c23cfb",
   "metadata": {},
   "source": [
    "Answer-PCA is closely related to feature extraction, as it involves deriving new features (principal components) that are linear combinations of the original features. PCA can be used for feature extraction by selecting a subset of principal components that capture the most significant variance in the data.\n",
    "\n",
    "Example:\n",
    "In a dataset containing multiple features representing different physical measurements, PCA can be used to extract new features that represent underlying patterns or trends in the data. For instance, the first principal component might represent overall body size, while the second principal component might capture variations in body proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89d872-62c3-4e5d-a9d9-66c5c1dbea41",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b4ffc-2c21-41c6-be88-2a0a47792b51",
   "metadata": {},
   "source": [
    "Answer- To preprocess the data for the recommendation system:\n",
    "\n",
    "Apply Min-Max scaling to features such as price, rating, and delivery time.\n",
    "For each feature, subtract the minimum value and divide by the range (maximum value minus minimum value) to scale the values between 0 and 1.\n",
    "This ensures that all features are on the same scale and prevents features with larger ranges from dominating the others during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8bf6c3-2746-4bcb-ba7f-a92113d4521a",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d069123d-81c5-4f34-b103-ee20ff04d700",
   "metadata": {},
   "source": [
    "Answer-To reduce the dimensionality of the dataset for predicting stock prices using PCA:\n",
    "\n",
    "Standardize the features to have zero mean and unit variance to ensure that all features contribute equally.\n",
    "Apply PCA to the standardized dataset to identify the principal components that capture the most variance.\n",
    "Select a subset of principal components that explain a significant portion of the variance (e.g., 95%).\n",
    "Use the selected principal components as input features for building the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfecb6d4-9051-4ba4-b8f9-f5d3f5b87c77",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f267c8d4-1ae8-4e11-a2ea-3bd08d57c6ce",
   "metadata": {},
   "source": [
    "Performing Min-Max scaling:\n",
    "Original values: \n",
    "[\n",
    "1\n",
    ",\n",
    "5\n",
    ",\n",
    "10\n",
    ",\n",
    "15\n",
    ",\n",
    "20\n",
    "]\n",
    "Original values: [1,5,10,15,20]\n",
    "Min-Max scaling: \n",
    "−\n",
    "min\n",
    "(\n",
    ")\n",
    "max\n",
    "(\n",
    ")\n",
    "−\n",
    "min\n",
    "(\n",
    ")\n",
    "Min-Max scaling:  \n",
    "max(x)−min(x)\n",
    "x−min(x)\n",
    "​\n",
    " \n",
    "Scaled values: \n",
    "[\n",
    "−\n",
    "1\n",
    ",\n",
    "−\n",
    "0.5\n",
    ",\n",
    "0\n",
    ",\n",
    "0.5\n",
    ",\n",
    "1\n",
    "]\n",
    "Scaled values:[-1,-0.5,0,0.5,1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59117fc-4cbd-416c-b8ce-f25169c55277",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dad023-2822-48ff-bcfe-cd14e4ab651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "For Feature Extraction using PCA on the dataset:\n",
    "\n",
    "Compute the covariance matrix of the features.\n",
    "Perform eigendecomposition to obtain the principal components and their corresponding eigenvalues.\n",
    "Choose the number of principal components to retain based on the cumulative explained variance (e.g., retaining components that explain 95% of the variance).\n",
    "Retain the principal components with the highest eigenvalues, as they capture the most significant variance in the data.For Feature Extraction using PCA on the dataset:\n",
    "\n",
    "Comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f0f34-5e8a-4acc-96f3-b19ad00199cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ad6c3-b6b7-4571-a382-7a8b3e316500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
